# Datasets Used in the TinyML Home Sound Classification Project

This project utilizes various sound datasets to train the machine learning model for sound classification in a home environment. Below are the descriptions and sources of the datasets used:

## Datasets

1. **UrbanSound8K**
   - **Description**: A dataset containing 8,732 labeled sound excerpts (less than 4 seconds) from urban environments. It includes sounds such as sirens, street music, and various human-made sounds.
   - **Source**: [UrbanSound8K Dataset](https://urbansounddataset.weebly.com/urbansound8k.html)

2. **AudioSet**
   - **Description**: A large-scale dataset of audio events, containing over 2 million human-labeled 10-second sound clips drawn from YouTube videos. It covers a wide range of sound categories.
   - **Source**: [AudioSet](https://research.google.com/audioset/)

3. **FSD50K**
   - **Description**: A dataset of 50,000 audio clips, each 10 seconds long, covering a wide variety of sound events. It is designed for sound event detection tasks.
   - **Source**: [FSD50K Dataset](https://github.com/mkhalil/FSD50K)

## Data Collection

The developer is responsible for collecting and preprocessing the sound data from these datasets to prepare it for training the machine learning model. The data will be used to train the model to classify various sounds relevant to a home environment, such as doorbells, telephones, and alarms.

## Usage

This README file serves as a guide for understanding the datasets used in the project. Further details on data preprocessing and model training can be found in the corresponding source code files.