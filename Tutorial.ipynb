{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf3cb0-2b43-48d4-96ce-f75f4f553239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import time\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import audio\n",
    "from mediapipe.tasks.python.audio.core import audio_record\n",
    "from mediapipe.tasks.python.components import containers\n",
    "\n",
    "model_path = 'E:/Software/Code/mediapipe_tutorial/lite-model_yamnet_classification_tflite_1.tflite'\n",
    "base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "\n",
    "# Define the variables with your desired values\n",
    "max_results = 5\n",
    "score_threshold = 0.5\n",
    "save_result = lambda result, timestamp: ... # You need to define this function\n",
    "\n",
    "# Now, the options call will work because the variables are defined\n",
    "options = audio.AudioClassifierOptions(\n",
    "    base_options=base_options,\n",
    "    max_results=max_results,\n",
    "    score_threshold=score_threshold,\n",
    "    result_callback=save_result,\n",
    "    running_mode=audio.RunningMode.AUDIO_STREAM)\n",
    "\n",
    "#Create the classifier object\n",
    "classifier = audio.AudioClassifier.create_from_options(options)\n",
    "\n",
    "buffer_size, sample_rate, num_channels = 15600, 16000, 1\n",
    "\n",
    "audio_format = containers.AudioDataFormat(\n",
    "    num_channels,\n",
    "    sample_rate)\n",
    "\n",
    "record = audio_record.AudioRecord(\n",
    "    num_channels,\n",
    "    sample_rate,\n",
    "    buffer_size)\n",
    "\n",
    "audio_data = containers.AudioData(buffer_size, audio_format)\n",
    "\n",
    "\n",
    "input_length_in_second = float(len(audio_data.buffer))/audio_data.audio_format.sample_rate\n",
    "\n",
    "overlapping_factor = 0.5\n",
    "\n",
    "interval_between_inference = input_length_in_second*(1-overlapping_factor)\n",
    "\n",
    "pause_time = interval_between_inference*0.1\n",
    "\n",
    "last_inference_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "200c3a72-aa0b-46ba-88b6-c363171cdeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top Classifications ---\n",
      "  - Category: Animal, Score: 0.9570\n",
      "  - Category: Domestic animals, pets, Score: 0.9180\n",
      "  - Category: Dog, Score: 0.9180\n",
      "  - Category: Bow-wow, Score: 0.5000\n",
      "--- Top Classifications ---\n",
      "  - Category: Animal, Score: 0.9180\n",
      "  - Category: Domestic animals, pets, Score: 0.8906\n",
      "  - Category: Dog, Score: 0.8906\n",
      "  - Category: Bow-wow, Score: 0.5859\n",
      "--- Top Classifications ---\n",
      "  - Category: Animal, Score: 0.9414\n",
      "  - Category: Domestic animals, pets, Score: 0.8906\n",
      "  - Category: Dog, Score: 0.8906\n",
      "  - Category: Bow-wow, Score: 0.5859\n",
      "--- Top Classifications ---\n",
      "  - Category: Animal, Score: 0.9570\n",
      "  - Category: Domestic animals, pets, Score: 0.9414\n",
      "  - Category: Dog, Score: 0.9414\n",
      "  - Category: Bow-wow, Score: 0.5859\n",
      "--- Top Classifications ---\n",
      "  - Category: Animal, Score: 0.9414\n",
      "  - Category: Domestic animals, pets, Score: 0.9180\n",
      "  - Category: Dog, Score: 0.9180\n",
      "  - Category: Bow-wow, Score: 0.5859\n",
      "--- Top Classifications ---\n",
      "  - Category: Animal, Score: 0.9688\n",
      "  - Category: Domestic animals, pets, Score: 0.9414\n",
      "  - Category: Dog, Score: 0.9414\n",
      "  - Category: Bow-wow, Score: 0.5000\n",
      "--- Top Classifications ---\n",
      "  - Category: Animal, Score: 0.9883\n",
      "  - Category: Domestic animals, pets, Score: 0.9805\n",
      "  - Category: Dog, Score: 0.9805\n",
      "  - Category: Bark, Score: 0.6680\n",
      "  - Category: Bow-wow, Score: 0.5000\n",
      "--- Top Classifications ---\n",
      "  - Category: Animal, Score: 0.9844\n",
      "  - Category: Domestic animals, pets, Score: 0.9570\n",
      "  - Category: Dog, Score: 0.9570\n",
      "  - Category: Bark, Score: 0.5000\n",
      "--- Top Classifications ---\n",
      "  - Category: Animal, Score: 0.9844\n",
      "  - Category: Domestic animals, pets, Score: 0.9688\n",
      "  - Category: Dog, Score: 0.9688\n",
      "  - Category: Bark, Score: 0.5859\n",
      "  - Category: Bow-wow, Score: 0.5000\n",
      "--- Top Classifications ---\n",
      "  - Category: Animal, Score: 0.9883\n",
      "  - Category: Domestic animals, pets, Score: 0.9805\n",
      "  - Category: Dog, Score: 0.9688\n",
      "  - Category: Bark, Score: 0.6680\n",
      "  - Category: Bow-wow, Score: 0.5000\n",
      "--- Top Classifications ---\n",
      "  - Category: Animal, Score: 0.8906\n",
      "  - Category: Domestic animals, pets, Score: 0.8516\n",
      "  - Category: Dog, Score: 0.8516\n",
      "  - Category: Bow-wow, Score: 0.5859\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import time\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import audio\n",
    "from mediapipe.tasks.python.components import containers\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "model_path = 'E:/Software/Code/mediapipe_tutorial/lite-model_yamnet_classification_tflite_1.tflite'\n",
    "base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "\n",
    "# Define the variables with your desired values\n",
    "max_results = 5\n",
    "score_threshold = 0.5\n",
    "save_result = lambda result, timestamp: ... # You need to define this function\n",
    "\n",
    "# Now, the options call will work because the variables are defined\n",
    "options = audio.AudioClassifierOptions(\n",
    "    base_options=base_options,\n",
    "    max_results=max_results,\n",
    "    score_threshold=score_threshold,\n",
    "    # result_callback=save_result,\n",
    "    running_mode=audio.RunningMode.AUDIO_CLIPS)\n",
    "\n",
    "# Load a saved audio file. Ensure it's resampled to 16kHz\n",
    "audio_file_path = 'dogbark.wav'\n",
    "y, sr = librosa.load(audio_file_path, sr=16000)\n",
    "\n",
    "# The audio data needs to be in a MediaPipe container\n",
    "audio_data = containers.AudioData(\n",
    "    buffer_length=len(y),\n",
    "    audio_format=containers.AudioDataFormat(\n",
    "        num_channels=1,\n",
    "        sample_rate=sr\n",
    "    )\n",
    ")\n",
    "audio_data.load_from_array(y.astype(np.float32))\n",
    "\n",
    "# Create the classifier object\n",
    "classifier = audio.AudioClassifier.create_from_options(options)\n",
    "\n",
    "# Run the inference on the audio data\n",
    "classification_result = classifier.classify(audio_data)\n",
    "\n",
    "\n",
    "# Assuming 'classification_result' is the list returned by classifier.classify(audio_data)\n",
    "\n",
    "# Check if the list of results is not empty\n",
    "if classification_result:\n",
    "    # Iterate through the list of results\n",
    "    for result in classification_result:\n",
    "        # Now, check if this individual result object has classifications\n",
    "        if result and result.classifications:\n",
    "            # We assume there's only one head (one set of scores)\n",
    "            categories = result.classifications[0].categories\n",
    "            print(\"--- Top Classifications ---\")\n",
    "            for category in categories:\n",
    "                # The category object contains the class name and score\n",
    "                print(f\"  - Category: {category.category_name}, Score: {category.score:.4f}\")\n",
    "        else:\n",
    "            print(\"No categories found in this result.\")\n",
    "else:\n",
    "    print(\"No classification results were returned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda99c4-3a1e-45b6-b5b3-9882dd2e644c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5d3f3e-03e4-436a-a222-c90ca758ed34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1114d3-0f1e-4a84-b8ea-692a3704f420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352ee17-fe11-434b-8143-52766baa50f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377990c-66ac-48b0-b4d3-d6087d52f83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540108a-cf66-4ede-a8cf-c437e19643df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4821b2b8-10e8-4cfe-9e83-feb4e07f752d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da8690-8e24-4a53-a85d-48614deb84aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5257622-06d7-4ecd-a4bc-0860d7a920d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a176f5-dbfb-474f-829a-cf474916f3ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "at(): incompatible function arguments. The following argument types are supported:\n    1. (self: mediapipe.python._framework_bindings.packet.Packet, arg0: int) -> mediapipe.python._framework_bindings.packet.Packet\n    2. (self: mediapipe.python._framework_bindings.packet.Packet, arg0: mediapipe.python._framework_bindings.timestamp.Timestamp) -> mediapipe.python._framework_bindings.packet.Packet\n\nInvoked with: <mediapipe.Packet with timestamp: UNSET and C++ type: class Eigen::Matrix<float,-1,-1,0,-1,-1>>, 1758634379807360600000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m data = record.read(buffer_size)\n\u001b[32m      2\u001b[39m audio_data.load_from_array(data)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclassify_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime_ns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Software\\Code\\mediapipe_tutorial\\venv\\Lib\\site-packages\\mediapipe\\tasks\\python\\audio\\audio_classifier.py:322\u001b[39m, in \u001b[36mAudioClassifier.classify_async\u001b[39m\u001b[34m(self, audio_block, timestamp_ms)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m audio_block.audio_format.sample_rate != \u001b[38;5;28mself\u001b[39m._default_sample_rate:\n\u001b[32m    315\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    316\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe audio sample rate provided in audio data: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    317\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_block.audio_format.sample_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is inconsistent with \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    318\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mthe previously received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._default_sample_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    320\u001b[39m \u001b[38;5;28mself\u001b[39m._send_audio_stream_data({\n\u001b[32m    321\u001b[39m     _AUDIO_IN_STREAM_NAME:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m         \u001b[43mpacket_creator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_block\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimestamp_ms\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m_MICRO_SECONDS_PER_MILLISECOND\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m })\n",
      "\u001b[31mTypeError\u001b[39m: at(): incompatible function arguments. The following argument types are supported:\n    1. (self: mediapipe.python._framework_bindings.packet.Packet, arg0: int) -> mediapipe.python._framework_bindings.packet.Packet\n    2. (self: mediapipe.python._framework_bindings.packet.Packet, arg0: mediapipe.python._framework_bindings.timestamp.Timestamp) -> mediapipe.python._framework_bindings.packet.Packet\n\nInvoked with: <mediapipe.Packet with timestamp: UNSET and C++ type: class Eigen::Matrix<float,-1,-1,0,-1,-1>>, 1758634379807360600000"
     ]
    }
   ],
   "source": [
    "data = record.read(buffer_size)\n",
    "audio_data.load_from_array(data)\n",
    "\n",
    "classifier.classify_async(audio_data, time.time_ns())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7e106-0ea8-438e-952f-224ae8857d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
